{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Operations\n",
    "\n",
    "In this notebook we will assemble our project.  We will explore different functions on our dataset and compile them into a workflow ready for production.\n",
    "\n",
    "The functions we will use will be a mix of `hub` based functions from our [MLRun Functions](http://github.com/mlrun/functions) repo, local and git based notebooks.\n",
    "\n",
    "> The notebook should be run after generating the data in the [Generator Notebook](generator.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will start by setting up our environment, Loading MLRun and some utilities we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "# MLRun imports\n",
    "from mlrun import mlconf\n",
    "\n",
    "# Setup API Endpoint\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you are using another version of our `hub://` please set it up in the following cell.\n",
    "* The url can parse {name} and {tag} to the given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hub URL address if using a local version\n",
    "# mlconf.hub_url = '/User/functions/{name}/function.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define our current project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project from a git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_project\n",
    "\n",
    "# update the dir and repo to reflect real locations \n",
    "# the remote git repo must be initialized in GitHub\n",
    "project_dir = os.path.abspath('./')\n",
    "remote_git = 'https://github.com/mlrun/demos.git'\n",
    "\n",
    "# Create the project\n",
    "newproj = new_project('network-operations', project_dir, init_git=False)\n",
    "\n",
    "# We can update our project directory to the latest status by running\n",
    "# newproj.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our project directory, lets forword our artifacts there to keep track of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an artifact path to keep track of where our artifacts are going\n",
    "ARTIFACT_PATH =  os.path.join(os.path.abspath(newproj.context), 'artifacts')\n",
    "mlconf.artifact_path = ARTIFACT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we receive a new dataset, the first thing we would like to do is to explore it a bit, we can do that using our `describe` function in `mlrun/functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mount_v3io, new_model_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f3ac82ca290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the functions\n",
    "# Functions From hub\n",
    "tag = 'dev-stream-concept-drift'\n",
    "newproj.set_function(func=f'hub://aggregate:{tag}', name='aggregate')\n",
    "newproj.set_function(func=f'hub://describe:{tag}', name='describe')\n",
    "newproj.set_function(func=f'hub://feature_selection:{tag}', name=\"feature_selection\")\n",
    "newproj.set_function(func=f'hub://sklearn_classifier:{tag}', name='train')\n",
    "newproj.set_function(func=f'hub://test_classifier:{tag}', name='test')\n",
    "newproj.set_function(func=f'hub://model_server_tester:{tag}', name=\"model_server-tester\")\n",
    "newproj.set_function(func=f'hub://concept_drift:{tag}', name=\"concept_drift\")\n",
    "newproj.set_function(func=f'hub://stream_to_parquet:{tag}', name=\"s2p\")\n",
    "newproj.set_function(func=f'hub://virtual_drift:{tag}', name=\"virtual_drift\")\n",
    "\n",
    "# Streaming\n",
    "src_path = os.path.abspath('notebooks/')\n",
    "newproj.set_function(func=os.path.join(src_path, 'generator.ipynb'), name='generator')\n",
    "newproj.set_function(func=os.path.join(src_path, 'preprocessor.ipynb'), name='create_feature_vector')\n",
    "newproj.set_function(func=os.path.join(src_path, 'server.ipynb'), name=\"serving\")\n",
    "newproj.set_function(func=os.path.join(src_path, 'labeled_stream_creator.ipynb'), name=\"labeled_stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset\n",
    "If needed go to [Generator](./notebooks/generator.ipynb) and run the local workflow to generate the metrics dataset to `data/metrics`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the functions locally to develop the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can **Run** the function locally on our sample data, we would like to get some details on our `raw` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register raw data as project level artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected /User/mlrun-demos/demos/network-operations/data/20201223T221512-20201223T231512.parquet as base dataset, Prepearing dataset\n",
      "Finished prepearing dataset (5768, 5), logging artifact to store://network-operations/metrics\n",
      "> 2020-12-24 08:11:49,787 [info] logging run results to: http://mlrun-api:8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.artifacts.dataset.DatasetArtifact at 0x7f3ac24840d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define base Dataset\n",
    "import random\n",
    "data_dir = os.path.join(os.path.abspath(newproj.context), 'data')\n",
    "dataset_filename = random.choice(list(filter(lambda x: (x.endswith('pq') or x.endswith('parquet')), os.listdir(data_dir))))\n",
    "metrics_path = os.path.join(data_dir, dataset_filename)\n",
    "print(f'Selected {metrics_path} as base dataset, Prepearing dataset')\n",
    "\n",
    "import pandas as pd\n",
    "# Drop alternate error columns\n",
    "label_column = 'is_error'\n",
    "raw = pd.read_parquet(metrics_path)\n",
    "raw = raw.drop([col for col in raw.columns if (col != label_column) & (col.endswith(label_column))], axis=1)\n",
    "dataset_path = os.path.join(data_dir, 'metrics.pq')\n",
    "raw.to_parquet(dataset_path)\n",
    "print(f'Finished prepearing dataset {raw.shape}, logging artifact to store://{newproj.name}/metrics')\n",
    "\n",
    "# Add to the project as a Dataset Artifact\n",
    "from mlrun.artifacts import DatasetArtifact\n",
    "from mlrun import get_or_create_ctx\n",
    "mlctx = get_or_create_ctx('netops-project')\n",
    "mlctx.log_dataset(key='metrics', df=raw, format='parquet', target_path=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics about the metrics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import NewTask\n",
    "from mlrun.platforms import auto_mount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_task = NewTask(\n",
    "    name=\"describe\", \n",
    "    handler=\"summarize\",  \n",
    "    params={\"key\": \"summary\", \n",
    "            \"label_column\": label_column, \n",
    "            'class_labels': ['0', '1'],\n",
    "            'plot_hist': True,\n",
    "            'plot_dest': 'plots-metrics'},\n",
    "    inputs={\"table\": metrics_path},\n",
    "    artifact_path=ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-20 15:15:49,311 [info] starting run describe uid=021253ee99794d1f884c4e658f38ed38 DB=http://mlrun-api:8080\n",
      "> 2020-12-20 15:15:49,454 [info] Job is running in the background, pod: describe-bq95d\n",
      "> 2020-12-20 15:15:59,545 [error] Failed to create pairplot histograms due to: Selected KDE bandwidth is 0. Cannot estiamte density.\n",
      "> 2020-12-20 15:16:02,266 [info] run executed, status=completed\n",
      "/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:288: UserWarning: Data must have variance to compute a kernel density estimate.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "final state: completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>network-operations</td>\n",
       "      <td><div title=\"021253ee99794d1f884c4e658f38ed38\"><a href=\"https://mlrun-ui.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/projects/network-operations/jobs/monitor/021253ee99794d1f884c4e658f38ed38/info\" target=\"_blank\" >...8f38ed38</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 20 15:15:56</td>\n",
       "      <td>completed</td>\n",
       "      <td>describe</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=orz</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=orz</div><div class=\"dictlist\">host=describe-bq95d</div></td>\n",
       "      <td><div title=\"/User/mlrun-demos/demos/network-operations/data/20201220T103437-20201220T113437.parquet\">table</div></td>\n",
       "      <td><div class=\"dictlist\">key=summary</div><div class=\"dictlist\">label_column=is_error</div><div class=\"dictlist\">class_labels=['0', '1']</div><div class=\"dictlist\">plot_hist=True</div><div class=\"dictlist\">plot_dest=plots-metrics</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result90ba9d7d\" title=\"/files/mlrun-demos/demos/network-operations/artifacts/plots/violin.html\">violin</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result90ba9d7d\" title=\"/files/mlrun-demos/demos/network-operations/artifacts/plots/imbalance.html\">imbalance</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result90ba9d7d\" title=\"/files/mlrun-demos/demos/network-operations/artifacts/plots/imbalance-weights-vec.csv\">imbalance-weights-vec</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result90ba9d7d\" title=\"/files/mlrun-demos/demos/network-operations/artifacts/plots/correlation-matrix.csv\">correlation-matrix</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result90ba9d7d\" title=\"/files/mlrun-demos/demos/network-operations/artifacts/plots/corr.html\">correlation</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result90ba9d7d-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result90ba9d7d-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result90ba9d7d\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result90ba9d7d-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 021253ee99794d1f884c4e658f38ed38 --project network-operations , !mlrun logs 021253ee99794d1f884c4e658f38ed38 --project network-operations\n",
      "> 2020-12-20 15:16:08,639 [info] run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "decsribe_run = newproj.func('describe').apply(auto_mount()).run(describe_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our [Aggregate](https://github.com/mlrun/functions/blob/master/aggregate/aggregate.ipynb) function to create rolling window features for our feature vector.\n",
    "\n",
    "In doing so we hope that we could help our algorithms identify local errors by using a windowed trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aggregate task\n",
    "from mlrun import NewTask\n",
    "aggregate_task = NewTask(\n",
    "    name='aggregate',\n",
    "    params={'metrics': ['cpu_utilization', 'throughput', 'packet_loss', 'latency'],\n",
    "            'metric_aggs': ['mean', 'sum', 'std', 'var', 'min', 'max', 'median'],\n",
    "            'suffix': 'daily',\n",
    "            'append_to_df': True,\n",
    "            'window': 20,\n",
    "            'center': False,\n",
    "            'save_to': os.path.join('data', 'aggregate.pq'),\n",
    "            'drop_na': True},\n",
    "    inputs={'df_artifact': f'store://{newproj.name}/metrics'},\n",
    "    handler='aggregate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-20 14:32:28,222 [info] starting run aggregate uid=6ff77910a9494210902c09baa558fdb9 DB=http://mlrun-api:8080\n",
      "> 2020-12-20 14:32:28,342 [info] Job is running in the background, pod: aggregate-vj4w5\n",
      "> 2020-12-20 14:32:31,813 [info] Aggregating /User/mlrun-demos/demos/network-operations/data/metrics.pq\n",
      "> 2020-12-20 14:32:31,923 [info] Logging artifact\n",
      "> 2020-12-20 14:32:32,190 [info] run executed, status=completed\n",
      "<string>:6: RuntimeWarning: Converting input from bool to <class 'numpy.uint8'> for compatibility.\n",
      "final state: completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>network-operations</td>\n",
       "      <td><div title=\"6ff77910a9494210902c09baa558fdb9\"><a href=\"https://mlrun-ui.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/projects/network-operations/jobs/monitor/6ff77910a9494210902c09baa558fdb9/info\" target=\"_blank\" >...a558fdb9</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Dec 20 14:32:31</td>\n",
       "      <td>completed</td>\n",
       "      <td>aggregate</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=orz</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=orz</div><div class=\"dictlist\">host=aggregate-vj4w5</div></td>\n",
       "      <td><div title=\"store://network-operations/metrics\">df_artifact</div></td>\n",
       "      <td><div class=\"dictlist\">metrics=['cpu_utilization', 'throughput', 'packet_loss', 'latency']</div><div class=\"dictlist\">metric_aggs=['mean', 'sum', 'std', 'var', 'min', 'max', 'median']</div><div class=\"dictlist\">suffix=daily</div><div class=\"dictlist\">append_to_df=True</div><div class=\"dictlist\">window=20</div><div class=\"dictlist\">center=False</div><div class=\"dictlist\">save_to=data/aggregate.pq</div><div class=\"dictlist\">drop_na=True</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"/User/mlrun-demos/demos/network-operations/artifacts/data/aggregate.pq\">aggregate</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultcf7dc9f9-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultcf7dc9f9-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultcf7dc9f9\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultcf7dc9f9-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 6ff77910a9494210902c09baa558fdb9 --project network-operations , !mlrun logs 6ff77910a9494210902c09baa558fdb9 --project network-operations\n",
      "> 2020-12-20 14:32:34,459 [info] run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "aggregate_run = newproj.func('aggregate').apply(mount_v3io()).run(aggregate_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics about the feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_describe_task = NewTask(\n",
    "    name=\"describe-aggregate\", \n",
    "    handler=\"summarize\",  \n",
    "    params={\"key\": \"summary\", \n",
    "            \"label_column\": label_column, \n",
    "            'class_labels': ['0', '1'],\n",
    "            'plot_hist': True,\n",
    "            'plot_dest': 'plots-aggregate',\n",
    "            'sample': 0.3},\n",
    "    inputs={\"table\": aggregate_run.outputs['aggregate']},\n",
    "    artifact_path=ARTIFACT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_decsribe_run = newproj.func('describe').apply(mount_v3io()).run(aggregate_describe_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create workflow to train the model\n",
    "After reviewing the data and creating the feature vector we move to training our model.  \n",
    "For this task we will use an **LGBM** classifier.  To control the training process we will supply a `model_config` dictionary with the following parameters:\n",
    "- **CLASS**: Model-specific parameters.\n",
    "- **FIT**: Training parameters (like epoch when needed)\n",
    "- **META**: Model and Package version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"CLASS\" : {\n",
    "        \"boosting_type\"      : \"gbdt\",\n",
    "        \"num_leaves\"         : 300,\n",
    "        \"max_depth\"          : 50,\n",
    "        \"learning_rate\"      : 0.1,\n",
    "        \"n_estimators\"       : 300,\n",
    "        \"objective\"          : \"binary\",\n",
    "        \"scale_pos_weight\"   : 1,    \n",
    "        \"min_split_gain\"     : 0.0,\n",
    "        \"min_child_samples\"  : 20,\n",
    "        \"subsample\"          : 1,\n",
    "        \"colsample_bytree\"   : 1,\n",
    "        \"reg_alpha\"          : 0,\n",
    "        \"reg_lambda\"         : 1,\n",
    "        \"n_jobs\"             : 16,\n",
    "        \"silent\"             : True,\n",
    "        \"importance_type\"    : \"split\",\n",
    "        \"random_state\"       : 1},\n",
    "    \"FIT\" : {\n",
    "        \"verbose\"               : False\n",
    "    },\n",
    "    \"META\" : {\n",
    "        \"class\" : \"lightgbm.sklearn.LGBMClassifier\",\n",
    "        \"version\" : \"2.3.1\"\n",
    "    }\n",
    "}\n",
    "model_config_path = os.path.join(os.path.abspath(newproj.context), 'data', 'lgb_model.json')\n",
    "with open(model_config_path, 'w') as f:\n",
    "          f.write(json.dumps(model_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "newproj.log_artifact('lgb_configs',\n",
    "                     target_path = os.path.abspath(model_config_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_stream:\n",
    "      name: labeled_stream\n",
    "      kind: v3ioStream\n",
    "      class: \"\"\n",
    "      maxWorkers: 1\n",
    "      url: \"http://v3io-webapi:8081\"\n",
    "      attributes:\n",
    "        jobBackoffLimit: 0\n",
    "        port: 0\n",
    "        consumerGroup: s2pt2\n",
    "        numContainerWorkers: 0\n",
    "        seekTo: latest\n",
    "        readBatchSize: 64\n",
    "        pollingIntervalMs: 500\n",
    "        containerName: users\n",
    "        streamPath: orz/mlrun-demos/demos/network-operations/streaming/labeled_stream\n",
    "        sequenceNumberCommitInterval: 1s\n",
    "        workerAllocationMode: pool\n",
    "        sessionTimeout: 10s\n",
    "        heartbeatInterval: 3s\n",
    "        fetchDefault: 0\n",
    "        intervalMs: 0\n",
    "        maxBatchSize: 0\n",
    "        maxBatchWaitMs: 0\n",
    "        protocolVersion: 0\n",
    "      disabled: false\n",
    "      password: 036f0244-f7a4-453b-b7d9-786172282378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/orz/mlrun-demos/demos/network-operations\n",
      "kind: remote\n",
      "metadata:\n",
      "  name: stream-to-parquet\n",
      "  tag: ''\n",
      "  hash: 3595515d13a017cbac762871f2294a5f89f6ab40\n",
      "  project: network-operations\n",
      "  labels:\n",
      "    author: orz\n",
      "  categories:\n",
      "  - ml\n",
      "  - serve\n",
      "spec:\n",
      "  command: ''\n",
      "  args: []\n",
      "  image: ''\n",
      "  entry_points:\n",
      "    record_to_features:\n",
      "      name: record_to_features\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: record\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 10\n",
      "    init_context:\n",
      "      name: init_context\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: context\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 17\n",
      "    handler:\n",
      "      name: handler\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: context\n",
      "        default: ''\n",
      "      - name: event\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 54\n",
      "  description: Saves a stream to Parquet and can lunch drift detection task on it\n",
      "  min_replicas: 1\n",
      "  max_replicas: 1\n",
      "  volumes: []\n",
      "  volume_mounts: []\n",
      "  env:\n",
      "  - name: window\n",
      "    value: '10'\n",
      "  - name: features\n",
      "    value: '[''cpu_utilization'', ''throughput'', ''packet_loss'', ''latency'']'\n",
      "  - name: save_to\n",
      "    value: /User/mlrun-demos/demos/network-operations/streaming/inference_pq\n",
      "  - name: base_dataset\n",
      "    value: /User/mlrun-demos/demos/network-operations/artifacts/test_set_preds.parquet\n",
      "  - name: results_tsdb_container\n",
      "    value: users\n",
      "  - name: results_tsdb_table\n",
      "    value: orz/mlrun-demos/demos/network-operations/streaming/s2p_tsdb\n",
      "  - name: mount_path\n",
      "    value: /users/orz\n",
      "  - name: mount_remote\n",
      "    value: /User\n",
      "  config:\n",
      "    spec.triggers.cron:\n",
      "      kind: cron\n",
      "      attributes:\n",
      "        interval: 1m\n",
      "    spec.triggers.labeled_stream:\n",
      "      kind: v3ioStream\n",
      "      url: http://v3io-webapi:8081\n",
      "      attributes:\n",
      "        containerName: users\n",
      "        streamPath: /orz/mlrun-demos/demos/network-operations/streaming/labeled_stream\n",
      "        consumerGroup: s2p\n",
      "        sequenceNumberCommitInterval: 1s\n",
      "        workerAllocationMode: pool\n",
      "        sessionTimeout: 10s\n",
      "        heartbeatInterval: 3s\n",
      "        seekTo: latest\n",
      "        readBatchSize: 64\n",
      "        pollingIntervalMs: 500\n",
      "      maxWorkers: 1\n",
      "      password: 036f0244-f7a4-453b-b7d9-786172282378\n",
      "  base_spec:\n",
      "    apiVersion: nuclio.io/v1\n",
      "    kind: Function\n",
      "    metadata:\n",
      "      annotations:\n",
      "        nuclio.io/generated_by: function generated from 23-07-2020 by admin\n",
      "      labels: {}\n",
      "      name: stream-to-parquet\n",
      "    spec:\n",
      "      build:\n",
      "        baseImage: mlrun/ml-models\n",
      "        commands: []\n",
      "        functionSourceCode: IyBHZW5lcmF0ZWQgYnkgbnVjbGlvLmV4cG9ydC5OdWNsaW9FeHBvcnRlcgoKaW1wb3J0IG9zCmltcG9ydCBwYW5kYXMgYXMgcGQKaW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBqc29uCmltcG9ydCBkYXRldGltZQppbXBvcnQgbWxydW4KCmRlZiByZWNvcmRfdG9fZmVhdHVyZXMocmVjb3JkKToKICAgIGZlYXR1cmVzID0gcmVjb3JkWydyZXF1ZXN0J11bJ2luc3RhbmNlcyddWzBdCiAgICB0aW1lc3RhbXAgPSByZWNvcmRbJ3doZW4nXQogICAgcHJlZGljdGlvbiA9IHJlY29yZFsncmVzcCddCiAgICAKICAgIHJldHVybiBbdGltZXN0YW1wXSArIFtmZWF0dXJlIGZvciBmZWF0dXJlIGluIGZlYXR1cmVzXSArIHByZWRpY3Rpb24KCmRlZiBpbml0X2NvbnRleHQoY29udGV4dCk6CiAgICBzZXRhdHRyKGNvbnRleHQsICdiYXRjaCcsIFtdKQogICAgc2V0YXR0cihjb250ZXh0LCAnd2luZG93JywgaW50KG9zLmdldGVudignd2luZG93JywgMTApKSkKICAgIAogICAgY29sdW1ucyA9IFtdCiAgICBmZWF0dXJlcyA9IG9zLmdldGVudignZmVhdHVyZXMnLCBOb25lKQogICAgaWYgZmVhdHVyZXMgaXMgbm90IE5vbmU6CiAgICAgICAgZmVhdHVyZXMgPSBmZWF0dXJlcy5zcGxpdCgnLCcpICAgIAogICAgICAgIGNvbHVtbnMgKz0gZmVhdHVyZXMKICAgIHNldGF0dHIoY29udGV4dCwgJ2ZlYXR1cmVzJywgZmVhdHVyZXMpCiAgICAgICAgCiAgICBwcmVkaWN0aW9ucyA9IG9zLmdldGVudigncHJlZGljdGlvbnMnLCBOb25lKQogICAgaWYgcHJlZGljdGlvbnMgaXMgbm90IE5vbmU6CiAgICAgICAgcHJlZGljdGlvbnMgPSBwcmVkaWN0aW9ucy5zcGxpdCgnLCcpCiAgICAgICAgY29sdW1ucyArPSBwcmVkaWN0aW9ucwogICAgICAgIAogICAgbGFiZWxfY29sID0gb3MuZ2V0ZW52KCdsYWJlbF9jb2wnLCBOb25lKQogICAgaWYgbGFiZWxfY29sIGlzIG5vdCBOb25lOgogICAgICAgIGxhYmVsX2NvbCA9IGxhYmVsX2NvbC5zcGxpdCgnLCcpCiAgICAgICAgY29sdW1ucyArPSBsYWJlbF9jb2wKICAgIHNldGF0dHIoY29udGV4dCwgJ2NvbHVtbnMnLCBbJ3RpbWVzdGFtcCddICsgY29sdW1ucykKICAgIAogICAgc2V0YXR0cihjb250ZXh0LCAnc2F2ZV90bycsIG9zLmdldGVudignc2F2ZV90bycsICcvYmlnZGF0YS9pbmZlcmVuY2VfcHEvJykpCiAgICBvcy5tYWtlZGlycyhjb250ZXh0LnNhdmVfdG8sIGV4aXN0X29rPVRydWUpCiAgICAKICAgIG1scnVuLm1sY29uZi5kYnBhdGggPSBtbHJ1bi5tbGNvbmYuZGJwYXRoIG9yICdodHRwOi8vbWxydW4tYXBpOjgwODAnCiAgICBpZiAnaHViX3VybCcgaW4gb3MuZW52aXJvbjoKICAgICAgICBtbHJ1bi5tbGNvbmYuaHViX3VybCA9IG9zLmVudmlyb25bJ2h1Yl91cmwnXQogICAgdmlydHVhbF9kcmlmdF9mbiA9IG1scnVuLmltcG9ydF9mdW5jdGlvbignaHViOi8vdmlydHVhbF9kcmlmdCcpCiAgICB2aXJ0dWFsX2RyaWZ0X2ZuLmFwcGx5KG1scnVuLm1vdW50X3YzaW8obmFtZT0ndmZuX21vdW50JywgbW91bnRfcGF0aD1vcy5nZXRlbnYoJ21vdW50X3BhdGgnLCAnfi8nKSwgcmVtb3RlPW9zLmdldGVudignbW91bnRfcmVtb3RlJywgJy9Vc2VyJykpKQogICAgc2V0YXR0cihjb250ZXh0LCAndmlydHVhbF9kcmlmdF9mbicsIHZpcnR1YWxfZHJpZnRfZm4pCiAgICBzZXRhdHRyKGNvbnRleHQsICdiYXNlX2RhdGFzZXQnLCBvcy5nZXRlbnYoJ2Jhc2VfZGF0YXNldCcsICcnKSkKICAgIAogICAgc2V0YXR0cihjb250ZXh0LCAnbGFiZWxfY29sJywgbGFiZWxfY29sKQogICAgc2V0YXR0cihjb250ZXh0LCAncmVzdWx0c190c2RiX2NvbnRhaW5lcicsIG9zLmdldGVudigncmVzdWx0c190c2RiX2NvbnRhaW5lcicsIE5vbmUpKQogICAgc2V0YXR0cihjb250ZXh0LCAncmVzdWx0c190c2RiX3RhYmxlJywgb3MuZ2V0ZW52KCdyZXN1bHRzX3RzZGJfdGFibGUnLCBOb25lKSkKCmRlZiBoYW5kbGVyKGNvbnRleHQsIGV2ZW50KToKICAgIAogICAgY29udGV4dC5sb2dnZXIuaW5mbyhmJ0FkZGluZyB7ZXZlbnQuYm9keX0nKQogICAgY29udGV4dC5iYXRjaC5hcHBlbmQocmVjb3JkX3RvX2ZlYXR1cmVzKGpzb24ubG9hZHMoZXZlbnQuYm9keSkpKQogICAgCiAgICBpZiBsZW4oY29udGV4dC5iYXRjaCkgPiBjb250ZXh0LndpbmRvdzoKICAgICAgICBjb250ZXh0LmxvZ2dlci5pbmZvKGNvbnRleHQuYmF0Y2gpCiAgICAgICAgZGYgPSBwZC5EYXRhRnJhbWUoZGF0YT1jb250ZXh0LmJhdGNoLAogICAgICAgICAgICAgICAgICAgICAgICAgIGNvbHVtbnM9Y29udGV4dC5jb2x1bW5zKQogICAgICAgIGRmX3BhdGggPSBvcy5wYXRoLmpvaW4oY29udGV4dC5zYXZlX3RvLCBmIntkYXRldGltZS5kYXRldGltZS5ub3coKS5zdHJmdGltZSgnJVktJW0tJWRUJUg6JU06JVMnKX0ucHEiKQogICAgICAgIGRmLnRvX3BhcnF1ZXQoZGZfcGF0aCkKCiAgICAgICAgdGFzayA9IG1scnVuLk5ld1Rhc2sobmFtZT0nZHJpZnRfbWFnbml0dWRlJywKICAgICAgICAgICAgICAgICAgICAgICAgaGFuZGxlcj0nZHJpZnRfbWFnbml0dWRlJywKICAgICAgICAgICAgICAgICAgICAgICAgcGFyYW1zPXsnbGFiZWxfY29sJzogY29udGV4dC5sYWJlbF9jb2wsCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ3Jlc3VsdHNfdHNkYl9jb250YWluZXInOiBjb250ZXh0LnJlc3VsdHNfdHNkYl9jb250YWluZXIsCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ3Jlc3VsdHNfdHNkYl90YWJsZSc6IGNvbnRleHQucmVzdWx0c190c2RiX3RhYmxlfSwKICAgICAgICAgICAgICAgICAgICAgICAgaW5wdXRzPXsndCc6IGNvbnRleHQuYmFzZV9kYXRhc2V0LAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICd1JzogZGZfcGF0aH0sCiAgICAgICAgICAgICAgICAgICAgICAgIGFydGlmYWN0X3BhdGg9bWxydW4ubWxjb25mLmFydGlmYWN0X3BhdGgpCiAgICAgICAgCiAgICAgICAgY29udGV4dC52aXJ0dWFsX2RyaWZ0X2ZuLnJ1bih0YXNrLAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgd2F0Y2g9RmFsc2UpCiAgICAgICAgCiAgICAgICAgY29udGV4dC5iYXRjaCA9IFtdCgo=\n",
      "        noBaseImagesPull: true\n",
      "      env: []\n",
      "      handler: stream_to_parquet:handler\n",
      "      runtime: python:3.6\n",
      "      volumes: []\n",
      "  source: ''\n",
      "  function_kind: mlrun\n",
      "verbose: false\n",
      "\n",
      "> 2020-12-24 08:12:15,745 [info] Starting remote function deploy\n",
      "2020-12-24 08:12:15  (info) Deploying function\n",
      "2020-12-24 08:12:15  (info) Building\n",
      "2020-12-24 08:12:15  (info) Staging files and preparing base images\n",
      "2020-12-24 08:12:15  (info) Building processor image\n",
      "2020-12-24 08:12:17  (info) Build complete\n",
      "2020-12-24 08:12:21  (info) Function deploy complete\n",
      "> 2020-12-24 08:12:21,368 [info] function deployed, address=default-tenant.app.lewpwntlsyrb.iguazio-cd1.com:32638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.lewpwntlsyrb.iguazio-cd1.com:32638'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "import copy\n",
    "fn = copy.copy(newproj.func('s2p'))\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "projdir = os.getcwd()\n",
    "projdir_path = f\"/{os.environ['V3IO_USERNAME']}{projdir[len('/User'):]}\"\n",
    "labeled_stream_path = os.path.join(projdir_path, 'streaming', 'labeled_stream')\n",
    "print(projdir_path)\n",
    "container = 'users'\n",
    "fn.add_trigger('cron', CronTrigger(interval='1m'))\n",
    "# fn.add_trigger('labeled_stream', V3IOStreamTrigger(url=f'https://webapi.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/{container}{labeled_stream_path}@s2p1'))\n",
    "fn.add_trigger('labeled_stream', V3IOStreamTrigger(container=container,\n",
    "                                                   path=labeled_stream_path,\n",
    "                                                   seekTo='latest',\n",
    "                                                   consumerGroup='s2p',\n",
    "                                                   url=\"https://webapi.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com\"))\n",
    "fn.set_envs({'window': 10,\n",
    "             'features': ['cpu_utilization', 'throughput', 'packet_loss', 'latency'],\n",
    "             'save_to': os.path.join(projdir, 'streaming', 'inference_pq'),\n",
    "             'base_dataset': '/User/mlrun-demos/demos/network-operations/artifacts/test_set_preds.parquet',\n",
    "             'results_tsdb_container': 'users',\n",
    "             'results_tsdb_table': 'orz/mlrun-demos/demos/network-operations/streaming/s2p_tsdb',\n",
    "             'mount_path': '/users/orz',\n",
    "             'mount_remote': '/User'})\n",
    "print(fn.to_yaml())\n",
    "fn.deploy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: remote\n",
      "metadata:\n",
      "  name: stream-to-parquet\n",
      "  tag: ''\n",
      "  hash: 3595515d13a017cbac762871f2294a5f89f6ab40\n",
      "  project: network-operations\n",
      "  labels:\n",
      "    author: orz\n",
      "  categories:\n",
      "  - ml\n",
      "  - serve\n",
      "spec:\n",
      "  command: http://default-tenant.app.lewpwntlsyrb.iguazio-cd1.com:32638\n",
      "  args: []\n",
      "  image: ''\n",
      "  entry_points:\n",
      "    record_to_features:\n",
      "      name: record_to_features\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: record\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 10\n",
      "    init_context:\n",
      "      name: init_context\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: context\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 17\n",
      "    handler:\n",
      "      name: handler\n",
      "      doc: ''\n",
      "      parameters:\n",
      "      - name: context\n",
      "        default: ''\n",
      "      - name: event\n",
      "        default: ''\n",
      "      outputs:\n",
      "      - default: ''\n",
      "      lineno: 54\n",
      "  description: Saves a stream to Parquet and can lunch drift detection task on it\n",
      "  min_replicas: 1\n",
      "  max_replicas: 1\n",
      "  volumes: []\n",
      "  volume_mounts: []\n",
      "  env:\n",
      "  - name: window\n",
      "    value: '10'\n",
      "  - name: features\n",
      "    value: '[''cpu_utilization'', ''throughput'', ''packet_loss'', ''latency'']'\n",
      "  - name: save_to\n",
      "    value: /User/mlrun-demos/demos/network-operations/streaming/inference_pq\n",
      "  - name: base_dataset\n",
      "    value: /User/mlrun-demos/demos/network-operations/artifacts/test_set_preds.parquet\n",
      "  - name: results_tsdb_container\n",
      "    value: users\n",
      "  - name: results_tsdb_table\n",
      "    value: orz/mlrun-demos/demos/network-operations/streaming/s2p_tsdb\n",
      "  - name: mount_path\n",
      "    value: /users/orz\n",
      "  - name: mount_remote\n",
      "    value: /User\n",
      "  config:\n",
      "    spec.triggers.labeled_stream:\n",
      "      kind: v3ioStream\n",
      "      url: https://webapi.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/users/orz/mlrun-demos/demos/network-operations/streaming/labeled_stream@s2p1\n",
      "      attributes:\n",
      "        seekTo: latest\n",
      "        readBatchSize: 64\n",
      "        pollingIntervalMs: 500\n",
      "      maxWorkers: 1\n",
      "      password: 036f0244-f7a4-453b-b7d9-786172282378\n",
      "    spec.triggers.cron:\n",
      "      kind: cron\n",
      "      attributes:\n",
      "        interval: 1m\n",
      "  base_spec:\n",
      "    apiVersion: nuclio.io/v1\n",
      "    kind: Function\n",
      "    metadata:\n",
      "      annotations:\n",
      "        nuclio.io/generated_by: function generated from 23-07-2020 by admin\n",
      "      labels: {}\n",
      "      name: stream-to-parquet\n",
      "    spec:\n",
      "      build:\n",
      "        baseImage: mlrun/ml-models\n",
      "        commands: []\n",
      "        functionSourceCode: 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\n",
      "        noBaseImagesPull: true\n",
      "      env: []\n",
      "      handler: stream_to_parquet:handler\n",
      "      runtime: python:3.6\n",
      "      volumes: []\n",
      "  source: ''\n",
      "  function_kind: mlrun\n",
      "verbose: false\n",
      "\n",
      "> 2020-12-23 11:43:10,046 [info] Starting remote function deploy\n",
      "2020-12-23 11:43:10  (info) Deploying function\n",
      "2020-12-23 11:43:10  (info) Building\n",
      "2020-12-23 11:43:10  (info) Staging files and preparing base images\n",
      "2020-12-23 11:43:10  (info) Building processor image\n",
      "2020-12-23 11:43:11  (info) Build complete\n",
      "2020-12-23 11:43:15  (info) Function deploy complete\n",
      "> 2020-12-23 11:43:16,191 [info] function deployed, address=default-tenant.app.lewpwntlsyrb.iguazio-cd1.com:32638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-tenant.app.lewpwntlsyrb.iguazio-cd1.com:32638'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "import copy\n",
    "fn = copy.copy(newproj.func('s2p'))\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "projdir = os.getcwd()\n",
    "projdir_path = projdir[len('/User'):]\n",
    "container = 'users'\n",
    "fn.add_trigger('cron', CronTrigger(interval='1m'))\n",
    "fn.add_trigger('labeled_stream', V3IOStreamTrigger(url='https://webapi.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/users/orz/mlrun-demos/demos/network-operations/streaming/labeled_stream@s2p1'))\n",
    "# fn.add_trigger('labeled_stream', V3IOStreamTrigger(container=container,\n",
    "#                                                    path=os.path.join(projdir_path, 'streaming', 'labeled_stream'),\n",
    "#                                                    seekTo='EARLIEST',\n",
    "#                                                    partitions=0,\n",
    "#                                                    consumerGroup='s2p'))\n",
    "fn.set_envs({'window': 10,\n",
    "             'features': ['cpu_utilization', 'throughput', 'packet_loss', 'latency'],\n",
    "             'save_to': os.path.join(projdir, 'streaming', 'inference_pq'),\n",
    "             'base_dataset': '/User/mlrun-demos/demos/network-operations/artifacts/test_set_preds.parquet',\n",
    "             'results_tsdb_container': 'users',\n",
    "             'results_tsdb_table': 'orz/mlrun-demos/demos/network-operations/streaming/s2p_tsdb',\n",
    "             'mount_path': '/users/orz',\n",
    "             'mount_remote': '/User'})\n",
    "print(fn.to_yaml())\n",
    "fn.deploy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/workflow.py\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io, mlconf\n",
    "import os\n",
    "from nuclio.triggers import V3IOStreamTrigger, CronTrigger\n",
    "\n",
    "funcs = {}\n",
    "projdir = os.getcwd()\n",
    "projdir_path = f\"/{os.environ['V3IO_USERNAME']}{projdir[len('/User'):]}\"\n",
    "labeled_stream_path = os.path.join(projdir_path, 'streaming', 'labeled_stream')\n",
    "container = 'users'\n",
    "full_path_projdir = os.path.join('/', container, os.environ[\"V3IO_USERNAME\"], projdir[6:])\n",
    "\n",
    "# Define a specific hub url?\n",
    "# mlconf.hub_url = 'https://raw.githubusercontent.com/mlrun/functions/{tag}/{name}/function.yaml'\n",
    "# mlconf.hub_url |= '/User/functions/{name}/function.yaml'\n",
    "\n",
    "model_inference_stream = os.path.join(full_path_projdir, 'streaming', 'predictions')\n",
    "labeled_stream = os.path.join(full_path_projdir, 'streaming', 'labeled_stream')\n",
    "\n",
    "webapi_url = 'http://v3io-webapi:8081'\n",
    "model_inference_url = f'{webapi_url}{model_inference_stream}'\n",
    "labeled_stream_url = f'{webapi_url}{labeled_stream}'\n",
    "\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        # Add V3IO Mount\n",
    "        f.apply(mount_v3io())\n",
    "        \n",
    "        # Always pull images to keep updates\n",
    "        f.spec.image_pull_policy = 'Always'\n",
    "    \n",
    "    # Define inference-stream related triggers\n",
    "    functions['s2p'].add_trigger('labeled_stream', V3IOStreamTrigger(container=container,\n",
    "                                                                     path=labeled_stream_path,\n",
    "                                                                     seekTo='earliest',\n",
    "                                                                     partitions=[0],\n",
    "                                                                     consumerGroup='s2p',\n",
    "                                                                     name='labeled_stream'))\n",
    "    functions['generator'].add_trigger('cron', CronTrigger(interval='1m'))\n",
    "    functions['labeled_stream'].add_trigger('cron', CronTrigger(interval='1m'))\n",
    "    functions['create_feature_vector'].add_trigger('cron', CronTrigger(interval='1m'))\n",
    "    functions['serving'].add_trigger('cron', CronTrigger(interval='1m'))\n",
    "                \n",
    "        \n",
    "@dsl.pipeline(\n",
    "    name='Network Operations Demo',\n",
    "    description='Train a Failure Prediction LGBM Model over sensor data'\n",
    ")\n",
    "def kfpipeline(\n",
    "        # aggregate\n",
    "        df_artifact = os.path.join(projdir, 'data', 'metrics.pq'),\n",
    "        metrics = ['cpu_utilization', 'throughput', 'packet_loss', 'latency'],\n",
    "        metric_aggs = ['mean', 'sum', 'std', 'var', 'min', 'max', 'median'],\n",
    "        suffix = 'daily',\n",
    "        window = 10,\n",
    "\n",
    "        # describe\n",
    "        describe_table = 'netops',\n",
    "        describe_sample = 0.3,\n",
    "        label_column = 'is_error',\n",
    "        class_labels = [1, 0],\n",
    "        plot_hist = True,\n",
    "    \n",
    "        # Feature selection\n",
    "        k = 5,\n",
    "        min_votes = 3,\n",
    "    \n",
    "        # Train\n",
    "        sample_size      = -1,        # -n for random sample of n obs, -1 for entire dataset, +n for n consecutive rows\n",
    "        test_size        = 0.1,       # 10% set aside\n",
    "        train_val_split  = 0.75,      # remainder split into train and val\n",
    "    \n",
    "        # Test\n",
    "        predictions_col = 'predictions',\n",
    "    \n",
    "        # Deploy\n",
    "        deploy_streaming = True,\n",
    "        aggregate_fn_url = 'hub://aggregate',\n",
    "        streaming_features_table = os.path.join(projdir, 'streaming', 'features'),\n",
    "        streaming_predictions_table = os.path.join(projdir, 'streaming', 'predictions'),\n",
    "    \n",
    "        # Streaming\n",
    "        streaming_metrics_table = os.path.join(projdir, 'streaming', 'metrics'),\n",
    "        generator_metrics_configuration = os.path.join(projdir, 'src', 'metric_configurations.yaml'),\n",
    "    \n",
    "        # labeled stream creator\n",
    "        streaming_labeled_table = labeled_stream,\n",
    "        \n",
    "        # Concept drift\n",
    "        deploy_concept_drift = True,\n",
    "        secs_to_generate = 10,\n",
    "        concept_drift_models = ['ddm', 'eddm', 'pagehinkley'],\n",
    "        output_tsdb = os.path.join(projdir, 'streaming', 'drift_tsdb'),\n",
    "        input_stream = labeled_stream_url,\n",
    "        output_stream = os.path.join(projdir, 'streaming', 'drift_stream'),\n",
    "        streaming_parquet_table =  os.path.join(projdir, 'streaming', 'inference_pq'),\n",
    "    \n",
    "        # Virtual drift\n",
    "        results_tsdb_container = 'users',\n",
    "        results_tsdb_table = os.path.join(full_path_projdir[7:], 'streaming', 'drift_magnitude')\n",
    "    ):\n",
    "    \n",
    "    # Run preprocessing on the data\n",
    "    aggregate = funcs['aggregate'].as_step(name='aggregate',\n",
    "                                                  params={'metrics': metrics,\n",
    "                                                          'metric_aggs': metric_aggs,\n",
    "                                                          'suffix': suffix,\n",
    "                                                          'window': window},\n",
    "                                                  inputs={'df_artifact': df_artifact},\n",
    "                                                  outputs=['aggregate'],\n",
    "                                                  handler='aggregate',\n",
    "                                                  image='mlrun/ml-models')\n",
    "\n",
    "    describe = funcs['describe'].as_step(name='describe-aggregation',\n",
    "                                        handler=\"summarize\",  \n",
    "                                        params={\"key\": f\"{describe_table}_aggregate\", \n",
    "                                                \"label_column\": label_column, \n",
    "                                                'class_labels': class_labels,\n",
    "                                                'plot_hist': plot_hist,\n",
    "                                                'plot_dest': 'plots/aggregation',\n",
    "                                                'sample': describe_sample},\n",
    "                                        inputs={\"table\": aggregate.outputs['aggregate']},\n",
    "                                        outputs=[\"summary\", \"scale_pos_weight\"])\n",
    "    \n",
    "    feature_selection = funcs['feature_selection'].as_step(name='feature_selection',\n",
    "                                                           handler='feature_selection',\n",
    "                                                           params={'k': k,\n",
    "                                                                   'min_votes': min_votes,\n",
    "                                                                   'label_column': label_column},\n",
    "                                                           inputs={'df_artifact': aggregate.outputs['aggregate']},\n",
    "                                                           outputs=['feature_scores', \n",
    "                                                                    'max_scaled_scores_feature_scores'\n",
    "                                                                    'selected_features_count', \n",
    "                                                                    'selected_features'],\n",
    "                                                           image='mlrun/ml-models')\n",
    "    \n",
    "    describe = funcs['describe'].as_step(name='describe-feature-vector',\n",
    "                                            handler=\"summarize\",  \n",
    "                                            params={\"key\": f'{describe_table}_features', \n",
    "                                                    \"label_column\": label_column, \n",
    "                                                    'class_labels': class_labels,\n",
    "                                                    'plot_hist': plot_hist,\n",
    "                                                    'plot_dest': 'plots/feature_vector'},\n",
    "                                            inputs={\"table\": feature_selection.outputs['selected_features']},\n",
    "                                            outputs=[\"summary\", \"scale_pos_weight\"])\n",
    "    \n",
    "    train = funcs['train'].as_step(name='train',\n",
    "                                   params={\"sample\"          : sample_size, \n",
    "                                           \"label_column\"    : label_column,\n",
    "                                           \"test_size\"       : test_size,\n",
    "                                           \"train_val_split\" : train_val_split},\n",
    "                                   inputs={\"dataset\"         : feature_selection.outputs['selected_features']},\n",
    "                                   hyperparams={'model_pkg_class': [\"sklearn.ensemble.RandomForestClassifier\", \n",
    "                                                                    \"sklearn.linear_model.LogisticRegression\",\n",
    "                                                                    \"sklearn.ensemble.AdaBoostClassifier\"]},\n",
    "                                   selector='max.accuracy',\n",
    "                                   outputs=['model', 'test_set'],\n",
    "                                   image='mlrun/ml-models')\n",
    "    \n",
    "    test = funcs['test'].as_step(name='test',\n",
    "                                 handler='test_classifier',\n",
    "                                 params={'label_column': label_column,\n",
    "                                         'predictions_column': predictions_col},\n",
    "                                 inputs={'models_path': train.outputs['model'],\n",
    "                                         'test_set': train.outputs['test_set']},\n",
    "                                 outputs=['test_set_preds'],\n",
    "                                 image='mlrun/ml-models')\n",
    "\n",
    "    \n",
    "    with dsl.Condition(deploy_streaming == True):\n",
    "        \n",
    "        # deploy the model using nuclio functions\n",
    "        deploy = funcs['serving'].deploy_step(env={'model_path': train.outputs['model'],\n",
    "                                                   'FEATURES_TABLE': streaming_features_table,\n",
    "                                                   'PREDICTIONS_TABLE': streaming_predictions_table,\n",
    "                                                   'prediction_col': predictions_col}, \n",
    "                                              tag='v1')\n",
    "\n",
    "        # test out new model server (via REST API calls)\n",
    "        tester = funcs[\"model_server-tester\"].as_step(name='model-tester',\n",
    "                                                      params={'addr': deploy.outputs['endpoint'], \n",
    "                                                              'model': \"predictor\",\n",
    "                                                              'label_column': label_column},\n",
    "                                                      inputs={'table': train.outputs['test_set']},\n",
    "                                                      outputs=['test_set_preds'])\n",
    "    \n",
    "        # Streaming demo functions\n",
    "        preprocessor = funcs['create_feature_vector'].deploy_step(env={ 'aggregate_fn_url': aggregate_fn_url,\n",
    "                                                                'METRICS_TABLE': streaming_metrics_table,\n",
    "                                                                'FEATURES_TABLE': streaming_features_table,\n",
    "                                                                'metrics': metrics,\n",
    "                                                                'metric_aggs': metric_aggs,\n",
    "                                                                'suffix': suffix,\n",
    "                                                                'base_dataset': train.outputs['test_set'],\n",
    "                                                                'label_col': label_column}).after(tester)\n",
    "\n",
    "        labeled_stream_creator = funcs['labeled_stream'].deploy_step(env={'METRICS_TABLE': streaming_metrics_table,\n",
    "                                                                                  'PREDICTIONS_TABLE': streaming_predictions_table,\n",
    "                                                                                  'OUTPUT_STREAM': streaming_labeled_table,\n",
    "                                                                                  'label_col': label_column,\n",
    "                                                                                  'prediction_col': predictions_col}).after(tester)\n",
    "\n",
    "        generator = funcs['generator'].deploy_step(env={'SAVE_TO': streaming_metrics_table,\n",
    "                                                        'SECS_TO_GENERATE': secs_to_generate,\n",
    "                                                        'METRICS_CONFIGURATION_FILEPATH': generator_metrics_configuration}).after(preprocessor)\n",
    "        \n",
    "        with dsl.Condition(deploy_concept_drift == True):\n",
    "\n",
    "            concept_builder = funcs['concept_drift'].deploy_step(skip_deployed=True)\n",
    "\n",
    "            concept_drift = funcs['concept_drift'].as_step(name='concept_drift_deployer',\n",
    "                                                           params={'models': concept_drift_models,\n",
    "                                                                   'label_col': label_column,\n",
    "                                                                   'prediction_col': predictions_col,\n",
    "                                                                   'output_tsdb': output_tsdb,\n",
    "                                                                   'input_stream': f'{input_stream}@cds',\n",
    "                                                                   'output_stream': output_stream},\n",
    "                                                           inputs={'base_dataset': test.outputs['test_set_preds']},\n",
    "                                                           artifact_path=mlconf.artifact_path,\n",
    "                                                           image=concept_builder.outputs['image']).after(labeled_stream_creator)\n",
    "\n",
    "            s2p = funcs['s2p'].deploy_step(env={'window': 10,\n",
    "                                                'features': metrics,\n",
    "                                                'save_to': streaming_parquet_table,\n",
    "                                                'base_dataset': test.outputs['test_set_preds'],\n",
    "                                                'results_tsdb_container': 'users',\n",
    "                                                'results_tsdb_table': results_tsdb_table,\n",
    "                                                'mount_path': '/users/orz',\n",
    "                                                'mount_remote': '/User'}).after(labeled_stream_creator)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newproj.set_workflow('main', os.path.join(os.path.abspath(newproj.context), 'src', 'workflow.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "newproj.save(os.path.join(newproj.context, 'project.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-23 14:16:49,325 [info] using in-cluster config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"['cpu_utilization', 'throughput', 'packet_loss', 'latency']\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"['mean', 'sum', 'std', 'var', 'min', 'max', 'median']\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"10\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.3\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[1, 0]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Boolean\" based on the value \"True\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"5\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"3\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"-1\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.1\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.75\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.7/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"['ddm', 'eddm', 'pagehinkley']\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/pipelines/#/experiments/details/07d4201d-d4bb-4a85-bb98-698407cdc83b\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.lewpwntlsyrb.iguazio-cd1.com/pipelines/#/runs/details/96bdd114-87a1-4ec3-802f-02f7232b2623\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-23 14:16:50,708 [info] Pipeline run id=96bdd114-87a1-4ec3-802f-02f7232b2623, check UI or DB for progress\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'96bdd114-87a1-4ec3-802f-02f7232b2623'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newproj.run('main', artifact_path=ARTIFACT_PATH, dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
